================================================================================
üì§ PUSH TO GITHUB AND USE ON KAGGLE - COMPLETE GUIDE
================================================================================

YOUR PLAN: ‚úÖ
1. Push all code to GitHub repo
2. In Kaggle: Clone repo + Download DRIVE dataset
3. Train with one command
4. Download trained model

================================================================================
STEP 1: PREPARE AND PUSH TO GITHUB (5 minutes)
================================================================================

Open PowerShell in your project folder and run:

```powershell
# Navigate to your project
cd "C:\Users\GAURAV PATIL\Desktop\gaurav's code\Project\unet\retina-unet-segmentation"

# Initialize git (if not already done)
git init

# Add all files
git add .

# Commit
git commit -m "Add optimized training code for Kaggle"

# Add your GitHub repo as remote (if not done)
git remote add origin https://github.com/Harshtherocking/retina-unet-segmentation.git

# Push to GitHub
git push -u origin main
```

If you get authentication error:
- Use GitHub Personal Access Token instead of password
- Or use GitHub Desktop application

================================================================================
STEP 2: CREATE KAGGLE NOTEBOOK (2 minutes)
================================================================================

1. Go to: https://www.kaggle.com/code
2. Click "New Notebook"
3. Settings (right panel):
   ‚úÖ Accelerator ‚Üí "GPU T4 x2"
   ‚úÖ Internet ‚Üí ON
4. Click "Save"

================================================================================
STEP 3: ADD DRIVE DATASET (1 minute)
================================================================================

1. In Kaggle notebook, click "Add Data" (right panel)
2. Search: "andrewmvd/drive-digital-retinal-images-for-vessel-extraction"
3. Click "Add"
4. Done! Dataset is now available

================================================================================
STEP 4: RUN TRAINING IN KAGGLE (30-40 minutes)
================================================================================

Copy-paste each CELL into your Kaggle notebook:

---
üìù CELL 1: Clone Repository and Setup
---
```python
# Clone your GitHub repository
!git clone https://github.com/Harshtherocking/retina-unet-segmentation.git
%cd retina-unet-segmentation

# Install dependencies
!pip install -q albumentations

print("‚úÖ Repository cloned!")
!ls
```

---
üìù CELL 2: Prepare DRIVE Dataset
---
```python
import kagglehub
import os
import shutil
from PIL import Image
import numpy as np

# Download DRIVE dataset from Kaggle
print("üì• Downloading DRIVE dataset...")
path = kagglehub.dataset_download("andrewmvd/drive-digital-retinal-images-for-vessel-extraction")
print(f"‚úÖ Dataset path: {path}")

# Create data directories
os.makedirs("data/train/image", exist_ok=True)
os.makedirs("data/train/mask", exist_ok=True)
os.makedirs("data/test/image", exist_ok=True)
os.makedirs("data/test/mask", exist_ok=True)

# Function to convert and copy images
def convert_and_copy(src_dir, dst_dir, is_mask=False):
    if not os.path.exists(src_dir):
        print(f"‚ö†Ô∏è  Directory not found: {src_dir}")
        return 0
    
    count = 0
    for file in os.listdir(src_dir):
        if file.endswith(('.tif', '.gif', '.png', '.jpg')):
            src_path = os.path.join(src_dir, file)
            
            # Clean filename
            dst_name = file.replace('.tif', '.png').replace('.gif', '.png')
            if '_manual1' in dst_name:
                dst_name = dst_name.replace('_manual1', '')
            
            dst_path = os.path.join(dst_dir, dst_name)
            
            # Convert and save
            img = Image.open(src_path)
            if is_mask:
                img = img.convert('L')  # Grayscale for masks
            else:
                img = img.convert('RGB')  # RGB for images
            img.save(dst_path, 'PNG')
            count += 1
    
    return count

# Copy training data
train_img_count = convert_and_copy(f"{path}/training/images", "data/train/image")
train_mask_count = convert_and_copy(f"{path}/training/1st_manual", "data/train/mask", is_mask=True)

# Copy test data
test_img_count = convert_and_copy(f"{path}/test/images", "data/test/image")
test_mask_count = convert_and_copy(f"{path}/test/1st_manual", "data/test/mask", is_mask=True)

print(f"\n‚úÖ Data prepared!")
print(f"   Training: {train_img_count} images, {train_mask_count} masks")
print(f"   Test: {test_img_count} images, {test_mask_count} masks")
```

---
üìù CELL 3: Update Configuration for Kaggle
---
```python
# Update config paths and parameters for Kaggle
with open('config_optimized.py', 'r') as f:
    config = f.read()

# Update paths
config = config.replace('TRAIN_IMG_DIR = "Retina/train/image"', 
                       'TRAIN_IMG_DIR = "data/train/image"')
config = config.replace('TRAIN_MASK_DIR = "Retina/train/mask"', 
                       'TRAIN_MASK_DIR = "data/train/mask"')
config = config.replace('TEST_IMG_DIR = "Retina/test/image"', 
                       'TEST_IMG_DIR = "data/test/image"')
config = config.replace('TEST_MASK_DIR = "Retina/test/mask"', 
                       'TEST_MASK_DIR = "data/test/mask"')

# Optimize for Kaggle GPU
config = config.replace('BATCH_SIZE = 4', 'BATCH_SIZE = 8')

with open('config_optimized.py', 'w') as f:
    f.write(config)

# Also update dataloader.py PATH
with open('dataloader.py', 'r') as f:
    dataloader = f.read()

dataloader = dataloader.replace('PATH = "Retina/train"', 'PATH = "data/train"')

with open('dataloader.py', 'w') as f:
    f.write(dataloader)

print("‚úÖ Configuration updated for Kaggle!")
```

---
üìù CELL 4: Check GPU and Configuration
---
```python
import torch
from config_optimized import *

print("="*70)
print("üöÄ KAGGLE TRAINING CONFIGURATION")
print("="*70)

if torch.cuda.is_available():
    print(f"\nüñ•Ô∏è  Device: {DEVICE}")
    print(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("\n‚ö†Ô∏è  No GPU detected!")

print(f"\nüìä Training Parameters:")
print(f"   Epochs: {EPOCHS}")
print(f"   Batch Size: {BATCH_SIZE}")
print(f"   Learning Rate: {LEARNING_RATE}")
print(f"   Loss Type: {LOSS_TYPE.upper()}")
print(f"   Augmentation: {USE_AUGMENTATION}")
print(f"   Mixed Precision: {USE_AMP}")

print("\n" + "="*70)
```

---
üìù CELL 5: üî• TRAIN MODEL (Main Training - 30-40 min)
---
```python
# Import and run training
import sys
sys.path.insert(0, '/kaggle/working/retina-unet-segmentation')

from train_optimized import train

print("\nüöÄ Starting training...")
print("‚è±Ô∏è  Expected time: 30-40 minutes on Kaggle T4 GPU")
print("üéØ Expected Dice: 75-82%\n")

# Run training
train()

print("\n‚úÖ Training complete!")
```

---
üìù CELL 6: Evaluate on Test Set
---
```python
import torch
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm
import numpy as np

from unet import Unet
from dataloader import ImageDataset
from config_optimized import *

# Load test dataset
test_dataset = ImageDataset(folder_path="data/test")
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Load best model
model = Unet(IN_CHANNELS, OUT_CHANNELS).to(DEVICE)
model.load_state_dict(torch.load('models/best_model.pth'))
model.eval()

# Calculate metrics
def calc_metrics(pred, target):
    pred = torch.softmax(pred, dim=1)[:, 1, :] > 0.5
    target = target.bool()
    
    tp = (pred & target).sum().float()
    fp = (pred & ~target).sum().float()
    tn = (~pred & ~target).sum().float()
    fn = (~pred & target).sum().float()
    
    dice = (2 * tp) / (2 * tp + fp + fn + 1e-8)
    iou = tp / (tp + fp + fn + 1e-8)
    acc = (tp + tn) / (tp + tn + fp + fn + 1e-8)
    
    return {'dice': dice.item(), 'iou': iou.item(), 'accuracy': acc.item()}

# Evaluate
metrics = {'dice': 0, 'iou': 0, 'accuracy': 0}

with torch.no_grad():
    for images, masks in tqdm(test_loader):
        images, masks = images.to(DEVICE), masks.to(DEVICE)
        outputs = model(images)
        m = calc_metrics(outputs, masks)
        for k in metrics: metrics[k] += m[k]

# Average
for k in metrics: metrics[k] /= len(test_loader)

print("\n" + "="*70)
print("üìä TEST SET RESULTS")
print("="*70)
print(f"üéØ Dice Score: {metrics['dice']:.4f}")
print(f"üéØ IoU: {metrics['iou']:.4f}")
print(f"üéØ Accuracy: {metrics['accuracy']:.4f}")
print("="*70)
```

---
üìù CELL 7: Visualize Results
---
```python
import matplotlib.pyplot as plt

def visualize(n=6):
    fig, axes = plt.subplots(n, 3, figsize=(15, n*5))
    model.eval()
    
    with torch.no_grad():
        for i in range(min(n, len(test_dataset))):
            img, mask = test_dataset[i]
            out = model(img.unsqueeze(0).to(DEVICE))
            pred = (torch.softmax(out, dim=1)[0, 1].cpu().numpy() > 0.5).astype(np.uint8)
            
            axes[i,0].imshow(img.permute(1,2,0).numpy())
            axes[i,0].set_title('Image')
            axes[i,0].axis('off')
            
            axes[i,1].imshow(mask.numpy(), cmap='gray')
            axes[i,1].set_title('Ground Truth')
            axes[i,1].axis('off')
            
            axes[i,2].imshow(pred, cmap='gray')
            axes[i,2].set_title('Prediction')
            axes[i,2].axis('off')
    
    plt.tight_layout()
    plt.show()

visualize(6)
```

---
üìù CELL 8: Download Trained Model
---
```python
from IPython.display import FileLink

print("="*70)
print("üì• DOWNLOAD YOUR TRAINED MODEL")
print("="*70)
print(f"\nüéâ Your model achieved {metrics['dice']:.4f} Dice score!")
print("\nClick below to download:")
display(FileLink('models/best_model.pth'))
print("\nüí° Use this model for inference on new retina images!")
print("="*70)
```

================================================================================
STEP 5: AFTER TRAINING - USE YOUR MODEL (Optional)
================================================================================

After downloading best_model.pth from Kaggle:

1. Copy to your local project: models/best_model.pth
2. Run inference:
   ```
   python inference.py --model models/best_model.pth --input image.png
   ```

================================================================================
‚úÖ COMPLETE WORKFLOW SUMMARY
================================================================================

GitHub (You) ‚Üí Kaggle (Clone) ‚Üí DRIVE Dataset ‚Üí Train ‚Üí Download Model

Time breakdown:
‚Ä¢ Push to GitHub: 5 min
‚Ä¢ Setup Kaggle: 3 min  
‚Ä¢ Run cells 1-4: 2 min
‚Ä¢ Training (Cell 5): 30-40 min
‚Ä¢ Evaluate & visualize: 2 min
‚Ä¢ Total: ~45-50 minutes

Expected result:
‚Ä¢ Dice Score: 75-82%
‚Ä¢ Accuracy: 95-96%
‚Ä¢ Production-ready model!

================================================================================
üéØ QUICK CHECKLIST
================================================================================

GitHub:
‚ñ° Push code to GitHub
‚ñ° Verify files are uploaded

Kaggle:
‚ñ° Create notebook
‚ñ° Enable GPU T4
‚ñ° Enable Internet
‚ñ° Add DRIVE dataset
‚ñ° Copy 8 cells from this guide
‚ñ° Run all cells
‚ñ° Wait ~40 minutes
‚ñ° Download best_model.pth

Done! ‚úÖ

================================================================================
üí° TIPS
================================================================================

‚Ä¢ Keep Kaggle tab open while training
‚Ä¢ Don't close browser during training
‚Ä¢ Kaggle auto-saves every 30 seconds
‚Ä¢ You can monitor progress in real-time
‚Ä¢ If interrupted, restart from Cell 5

================================================================================

Ready? Push to GitHub and start training on Kaggle! üöÄ

================================================================================
